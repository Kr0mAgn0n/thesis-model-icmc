Neste capítulo apresentará-se um resumo da teoria de variedades riemannianas.
Tomou-se como referencia principal os livros \cite{Lee2012}, \cite{Lee1997}, \cite{Carmo1988} e \cite{Gallot2004}.
O conteúdo de este capítulo servirá como marco teórico para o desenvolvimento dos capítulos seguintes.

\section{Variedades riemannianas}

As variedades riemannianas aparecem de uma variedade diferenciável adicionando uma métrica.
Essa métrica é um produto interno em cada espaço tangente da variedade e permite medir comprimentos onde inicialmente não era possível.
Em esta seção apresentará-se a definição de variedade riemanniana e as suas propriedades.
Também mostrará-se o conceito de isometria entre duas variedades riemannianas.
As isometrias definem uma equivalência entre duas variedades riemannianas.
Essa equivalência pode ser local o global.
A teoria de variedades riemannianas é a base de todo o mostrado em esta dissertação.

\begin{definicao}
	Seja $M$ uma variedade diferenciável. Uma \emph{métrica riemanniana em $M$} é um campo 2-tensorial covariante, simétrico e diferenciável que é definido positivo em cada ponto.	
\end{definicao}

\begin{definicao}
	Uma \emph{variedade riemanniana} é um par $(M,g)$, onde $M$ é uma variedade diferenciável e $g$ é uma métrica riemanniana em $M$.
\end{definicao}

\begin{observacao}
	Para qualquer carta $(x_1, \ldots, x_n)$, uma métrica riemanniana pode ser escrita como
	\begin{equation*}
		g = \sum_{i,j=1}^n g_{ij} dx_i \otimes dx_j
	\end{equation*}
	onde $(g_{ij})$ é uma matriz definida positiva simétrica de funções diferenciáveis.
\end{observacao}

\begin{proposicao}
Toda variedade diferenciável admite uma métrica riemanniana.
\end{proposicao}


\begin{demonstracao}
	Seja $M$ uma variedade diferenciável e $\{ (U_{\alpha}, \varphi_{\alpha}) \}_{\alpha \in A}$ um atlas diferenciável, onde $A$ e um conjunto de índices. Em cada $U_{\alpha}$ tem-se a métrica
	\begin{equation*}
		g_{\alpha} = \varphi_{\alpha}^* \overline{g}
	\end{equation*}
	onde $\overline{g}$ é a métrica euclideana e $\varphi_{\alpha}^*$ é um pullback tensorial. Seja $(\psi_{\alpha})_{\alpha \in A}$ a partição da unidade subordinada à cobertura $(U_{\alpha})_{\alpha \in A}$. Definimos $g: M \rightarrow T^2(M)$, tal que
	\begin{equation*}
		g = \sum_{\alpha \in A} \psi_{\alpha} g_{\alpha}.
	\end{equation*}
	Seja $p \in M$, $U_{\alpha_0}$ aberto da cobertura tal que $p \in U_{\alpha_0}$ e $v,w \in T_pM$. Então
	\begin{align*}
		g_p(v,w) &= \sum_{\alpha \in A} \psi_{\alpha}(p) g_{\alpha | p}(v,w)\\
		&= \sum_{\alpha \in A} \psi_{\alpha}(p) \varphi_{\alpha}^* \overline{g}(v,w)\\
		&= \sum_{\alpha \in A} \psi_{\alpha}(p) \varphi_{\alpha}^* \overline{g}(w,v)\\
		&= g_p(w,v)
	\end{align*}
	Tem-se que $g_p$ é simétrica. Olhar que a convergência da soma está garantida porque $(\psi_{\alpha})_{\alpha \in A}$ é uma partição da unidade. Por outro lado, para $v \in T_pM$ não nulo tem-se
	\begin{equation*}
		g_p(v,v) = \sum_{\alpha \in A} \psi_{\alpha}(p) \varphi_{\alpha}^* \overline{g}(v,v).
	\end{equation*}
	Olhar que $\varphi_{\alpha}^* \overline{g}(v,v) > 0$ porque $\overline{g}$ é a métrica euclideana. Seja $W$ um aberto da cobertura tal que $p \in W$. Então existem $\{ \alpha_1, \ldots, \alpha_n \} \subset A$ tal que $\text{supp} \psi_{\alpha_i} \cap W \neq \emptyset$ para $i=1, \ldots, n$, e para os índices restantes a interseção é vazia. Logo, a equação anterior escreve-se
	\begin{equation*}
	g_p(v,v) = \sum_{i=1}^n \psi_{\alpha_i}(p) \varphi_{\alpha_i}^* \overline{g}(v,v).
	\end{equation*}
	Como $0 \leq \psi_{\alpha_i}(p) \leq 1$ e $\sum_{i=1}^n \psi_{\alpha_i}(p) = 1$ para qualquer $p \in M$ onde $i=1,\ldots,n$, então $g_p(v,v) > 0$. Logo, $g_p$ é positiva. Portanto, $g$ é uma métrica riemanniana.
\end{demonstracao}

\begin{proposicao}
	Supor que $(M,g)$ é uma variedade riemanniana, e $(X_j)$ é um referencial local diferenciável para $M$ sobre um subconjunto aberto $U \subset M$. Então, existe um referencial ortonormal diferenciável $\{ (E_j)\}$ sobre $U$ tal que
	\begin{equation*}
		\text{span} \{ X_{1|p}, \ldots, X_{n|p} \} = \text{span} \{ E_{1|p}, \ldots, E_{n|p} \}
	\end{equation*}
	para cada $ j=1, \ldots, n $ e $p \in U$.
\end{proposicao}

\begin{demonstracao}
	Supor que $M$ é uma variedade riemanniana de dimensão $n$ e seja $p \in U$, onde $U$ é um aberto de $M$. O conjunto $\{ X_{1|p},\ldots,X_{n|p} \}$ é uma base de $T_pM$. Pelo algoritmo de Gram-Schmidt pudemos obter uma base ortonormal $\{ E_{1|p},\ldots,E_{n|p} \}$ de $T_pM$ para todo $p \in U$. Portanto, $\{ E_1,\ldots,E_n \}$ é um referencial local diferenciável.
\end{demonstracao}

\begin{corolario}
	Seja $(M,g)$ uma variedade riemanniana. Para cada $p \in M$, existe um referencial ortonormal diferenciável em uma vizinhança de $p$.
\end{corolario}

\begin{demonstracao}
	Só definir qualquer referencial local diferenciável para obter um referencial local diferenciável ortonormal.
\end{demonstracao}

%\section{Isometrias}





\begin{definicao}\label{metrica_pullback}
	Supor que $M,N$ são variedades diferenciáveis, $g$ é uma métrica Riemanniana em $N$, e $F: M \rightarrow N$ é diferenciável. O \emph{pullback} $F^* g$ é um campo 2-tensorial diferenciável em $M$. Se é definido positivo, é uma métrica riemanniana em $M$, chamada de \emph{métrica pullback} determinada pelo $F$.
\end{definicao}

\begin{proposicao}
	Supor que $F: M \rightarrow N$ é uma função diferenciável e $g$ é a métrica riemanniana em $N$. Então, $F^* g$ é uma métrica riemanniana em $M$ se e somente se $F$ é uma imersão diferenciável.
\end{proposicao}

\begin{demonstracao}
	Supor que $F^*g$ é uma métrica riemanniana. Seja $p \in M$ e $v \in T_pM$ não nulo, então
	\begin{equation*}
		0 < F^*g(v,v) = g(dF_p v, dF_p v).
	\end{equation*}
	Como $g$ é métrica riemanniana, tem-se que $dF_p v \neq 0$. Logo $dF_p$ é injetora concluindo que $F$ é uma imersão diferenciável.
	Agora supor que $F$ é uma imersão diferenciável, $p \in M$ e $v \in T_pM$ não nulo. Como $dF_p$ injetora, tem-se que $dF_p v \neq 0$. Como $g$ é uma métrica riemanniana, tem-se
	\begin{equation*}
		0 < g(dF_p v, dF_p v) = F^*g(v,v).
	\end{equation*}
	Portanto, $F* g$ é uma métrica riemanniana.
\end{demonstracao}

\begin{definicao}
	Se $(M,g)$ e $(\tilde{M}, \tilde{g})$ são variedades riemannianas, a função diferenciável $F: M \rightarrow \tilde{M}$ é chamada de \emph{isometria} se é um difeomorfismo que satisfaz $F^* \tilde{g} = g$.
\end{definicao}

\begin{observacao}
	Mais geralmente, $F$ é chamada de \emph{isometria local} se para cada ponto $p \in M$ existe uma vizinhança $U$ tal que $F_{|U}$ é uma isometria de $U$ com um subconjunto aberto de $\tilde{M}$.
\end{observacao}

\begin{observacao}
	Se existe uma isometria entre $(M,g)$ e $(\tilde{M}, \tilde{g})$, dizemos que ambos são variedades riemannianas isométricas e se existe uma isometria local entre elas, então são chamadas de variedades riemannianas localmente isométricas.
\end{observacao}

%\begin{observacao}
%	O conceito de isometria define uma equivalência entre duas variedades riemannianas.
%	Esta equivalência pode ser local o global.
%\end{observacao}

%\begin{definicao}
%	Uma $n$-variedade riemanniana é chamada de \emph{variedade riemanniana flat}, e $g$ é uma \emph{métrica flat}, se $(M,g)$ é localmente isométrica a $(\mathbb{R}^n,\overline{g})$.
%\end{definicao}

%\begin{observacao}
%	Existem métricas riemannianas que não são planas.
%\end{observacao}



%\section{Fibrado Normal}
%
%\begin{definicao}
%	Supor que $(M,g)$ é uma $n$-variedade Riemanniana, e $S \subset M$ é uma $k$-subvariedade Riemanniana. Para qualquer $p \in S$, dizemos que um vetor $v$ é \emph{normal a S}  se é ortogonal a todo vetor em $T_p S$ com respeito ao produto interno $\langle , \rangle_g$.
%\end{definicao}
%
%\begin{definicao}
%	O \emph{espaço normal a S em} $p$ é o subespaço $N_p S \subset T_p M$ que consiste de todos os vetores que são normais a $S$ em $p$.
%\end{definicao}
%
%\begin{definicao}
%	O \emph{fibrado normal de} $S$ é o subconjunto $NS \subset TM$ que consiste da união de todos os espaços normais aos ponto de $S$.
%\end{definicao}
%
%\begin{definicao}
%	A projeção $\pi_{NS}: NS \rightarrow S$ é a restrição a $NS$ da projeção $\pi: TM \rightarrow M$.
%\end{definicao}

\section{Conexões lineares}

As conexões lineares são definidas para satisfazer a necessidade de ter uma ``derivação'' de campos vetoriais em uma variedade diferenciável.
Em esta seção apresentará-se resultados sobre a sua existência e as suas propriedades.
Posteriormente, a conexão linear será usada para definir a conexão riemanniana, que é importante para o desenvolvimento do conceito de curvatura.

\begin{definicao}
	Uma \emph{conexão linear} numa variedade diferenciável $M$ é uma função
	\begin{equation*}
		\nabla: \mathfrak{X}(M) \times \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)
	\end{equation*}
	tal que para $X,Y \in \mathfrak{X}(M)$, satisfaz as propriedades
	\begin{enumerate}
		\item $\nabla_X Y$ é linear sobre $C^\infty (M)$ em $X$, i.e.,
		\begin{equation*}
			\nabla_{f X_1 + g X_2} Y = f \nabla_{X_1} Y + g \nabla_{X_2} Y
		\end{equation*}
		para $f,g \in C^{\infty} (M)$.
		
		\item $\nabla_X Y$ é linear sobre $\mathbb{R}$ em $Y$, i.e.,
		\begin{equation*}
			\nabla_X (a Y_1 + b Y_2) = a \nabla_X Y_1 + b \nabla_X Y_2
		\end{equation*}
		para $a,b \in \mathbb{R}$.
		
		\item $\nabla$ satisfaz a seguente regra:
		\begin{equation*}
			\nabla_X (f Y) = f \nabla_X Y + (X f) Y
		\end{equation*}
		para $f \in C^{\infty}(M)$.
	\end{enumerate}
\end{definicao}

\begin{observacao}
	$\nabla_X Y$ é também chamado de \emph{derivada covariante de} $Y$ na direção de $X$.
\end{observacao}

\begin{proposicao}\label{boa_definicao_conexao_1}
	Se $\nabla$ é uma conexão linear de uma variedade diferenciável $M$, $X,Y \in \mathfrak{X}(M)$, e $p \in M$, então $\nabla_X Y_{|p}$ depende só dos valores de $X$ e $Y$ numa vizinhança pequena de $p$, i.e., se $X = \tilde{X}$ e $Y = \tilde{Y}$ numa vizinhança pequena de $p$, então $\nabla_X Y_{|p} = \nabla_{\tilde{X}} \tilde{Y}_{|p}$.
\end{proposicao}

\begin{demonstracao}
	Seja $p \in M$ e $U$ um aberto de $M$ tal que $p \in U$. Tem-se que $X = \tilde{X}$ e $Y = \tilde{Y}$ em $U$. Definamos $Z = Y - \tilde{Y}$ e $\varphi: M \rightarrow \realnumbers$ tal que $\varphi(p)=1$ e $\supp \varphi \subset U$. Pode-se ver que $\varphi Z \equiv 0$ e
	\begin{equation*}
		\nabla_X (\varphi Z) = (X \varphi) Z + \varphi \nabla_X Z.
	\end{equation*}
	Também pode-ser ver que
	\begin{equation*}
		\nabla_X (\varphi Z)  = \nabla_X (0 . \varphi Z) = 0 . \nabla_X (\varphi Z) = 0.
	\end{equation*}
	Avaliando a primeira equação em $p$ tem-se
	\begin{equation*}
		0 = (\varphi \nabla_X Z)_p = \varphi(p) (\nabla_X Z)_p = (\nabla_X Z)_p.
	\end{equation*}
	Então $(\nabla_X Y)_p = (\nabla_X \tilde{Y})_p$ para qualquer $p \in M$.
	Por outro lado, definamos $W = X - \tilde{X}$. Tem-se que $W(p) = 0$ para $p \in U$. Usando a mesma função $\varphi$ definida anteriormente, tem-se que $\varphi W \equiv 0$ em $M$, Logo
	\begin{align*}
		\nabla_{\varphi W} Y &= \nabla_{0 . \varphi W} Y\\
		&= 0 . \nabla_{\varphi W} Y\\
		&= 0,
	\end{align*}
	onde $0$ é a função nula. Mas
	\begin{equation*}
		\nabla_{\varphi W} Y = \varphi \nabla_W Y.
	\end{equation*}
	Avaliando em $p$ tem-se
	\begin{align*}
		0 = (\nabla_{\varphi W} Y)_p &= \varphi(p) (\nabla_W Y)_p\\
		&= (\nabla_W Y)_p.
	\end{align*}
	Então
	\begin{equation*}
		(\nabla_X Y)_p = (\nabla_{\tilde{X}} Y)_p.
	\end{equation*}
	Portanto $(\nabla_X Y)_p = (\nabla_{\tilde{X}} \tilde{Y})_p$.
\end{demonstracao}

\begin{proposicao}\label{boa_definicao_conexao_2}
	No lema \ref{boa_definicao_conexao_1}, se pode adicionar que $\nabla_X Y_{|p}$ depende só dos valores de $Y$ numa vizinhança pequena de $p$ e do valor de $X$ em $p$.
\end{proposicao}

\begin{demonstracao}
	Seja $U$ aberto de $M$ e $X, \tilde{X} \in \vectorfieldsspace{U}$ tal que $X_p = \tilde{X}_p$ para $p \in U$. Definamos $W \in \vectorfieldsspace{U}$ tal que $W = X - \tilde{X}$. Pode-se ver que $W_p = 0$. Usando o sistema de coordenadas canônicas tem-se que $W = W^i \partial_i$. Logo
	\begin{align*}
		(\nabla_W Y)_p &= (\nabla_{W^i \partial_i} Y)_p\\
		&=   W^i(p) (\nabla_{\partial_i} Y)_p\\
		&= 0
	\end{align*}
	Portanto $(\nabla_X Y)_p = (\nabla_{\tilde{X}} Y)_p$, i.e., depende só do valor de $X$ em $p$.
\end{demonstracao}

\begin{observacao}
	Pelo lema \ref{boa_definicao_conexao_2}, podemos escrever $\nabla_{X_p} Y$ em lugar de $\nabla_X Y_{|p}$, i.e., podemos dizer que é a derivada direcional de $Y$ em $p$ com direção $X_p$.
\end{observacao}



\begin{observacao}\label{obs_simbolos_christoffel}
	Seja $M$ uma variedade diferenciável, e $(E_i)$ um referencial local de $TM$ num conjunto aberto $U \subset M$. Para qualquer escolha de índices $i$ e $j$, podemos expandir $\nabla_{E_i} E_j$ em termos do mesma referencial
	\begin{equation*}
		\nabla_{E_i} E_j = \Gamma^k_{ij} E_k
	\end{equation*}
	Isto define $n^3$ funções $\Gamma^k_{ij}$ em $U$.
\end{observacao}

\begin{definicao} 
	As funções definidas na observação \ref{obs_simbolos_christoffel} , são chamadas de \emph{símbolos de Christoffel} de $\nabla$ com respeito ao referencial dado.
\end{definicao}

\begin{lema}\label{conexiones lineales en función de símbolos de Chritoffel}
	Seja $\nabla$ uma conexão afim, e seja $X,Y \in \mathfrak{X}(M)$ tal que tal que são expressados em termos um referencial local por $X = X^i E_i$ e $Y = Y^j E_j$. Então
	\begin{equation*}
		\nabla_X Y = \left( X Y^k + X^i Y^j \Gamma^k_{ij} \right) E_k
	\end{equation*}
\end{lema}

\begin{demonstracao}
	Tem-se
	\begin{align*}
		\nabla_X Y &= \nabla_X (Y^j E_j)\\
		&= X Y^j E^j + Y^j \nabla_X E_j\\
		&= X Y^j E^j + Y^j X^i \nabla_{E_i} E_j\\
		&= X Y^j E^j + Y^j X^i \Gamma^k_{ij} E_k.
	\end{align*}
	Mudando o índice do primeiro somando tem-se
	\begin{align*}
		\nabla_X Y &= X Y^k E^k + Y^j X^i \Gamma^k_{ij} E_k\\
		&= (X Y^k + Y^j X^i \Gamma^k_{ij}) E_k.
	\end{align*}
\end{demonstracao}

\begin{proposicao}\label{derivada-covariante-de-um-caminho}
	Seja $M$ uma variedade diferenciável e
	$\nabla$ uma conexão linear de $M$.
	Cada caminho $\lambda: I \rightarrow M$, $\nabla$ determina um operador único
	\begin{equation*}
	D_t: \vectorfieldsspace{\lambda} \rightarrow \vectorfieldsspace{\lambda}
	\end{equation*}
	que satisfaz as seguintes propriedades:
	\begin{enumerate}
		\item Seja $X,Y \in \vectorfieldsspace{\lambda}$ e $a,b \in \R$. Então
		\begin{equation*}
		D_t(aX + bY) = a D_t X + b D_t Y
		\end{equation*}
		\item Seja $X \in \vectorfieldsspace{\lambda}$ e $f \in C^{\infty}(I)$. Então
		\begin{equation*}
		D_t(fX) = f' X + f D_t X
		\end{equation*}
		\item Se $X \in \vectorfieldsspace{\lambda}$ é extensível, então para toda extensão $\tilde{X}$ de $X$,
		\begin{equation*}
		D_t X(t) = \nabla_{\lambda'(t)} \tilde{X}
		\end{equation*}
	\end{enumerate}
\end{proposicao}

\begin{demonstracao}
	Supor que $D_t$ existe e tem as propriedades anteriormente mencionadas.
	Então,
	\begin{align*}
	D_t V(t) &= D_t \left(V^i(t) \partial_i\right)\\
	&= (V^i)'(t) \partial_i + V^i(t) D_t \partial_i\\
	&= (V^i)'(t) \partial_i + V^i(t) \nabla_{\lambda'(t)} \partial_i\\
	&= (V^i)'(t) \partial_i + V^i(t) \nabla_{(\lambda^j)'(t) \partial_j} \partial_i\\
	&= (V^i)'(t) \partial_i + V^i(t) (\lambda^j)'(t)  \nabla_{\partial_j} \partial_i\\
	&= (V^i)'(t) \partial_i + V^i(t) (\lambda^j)'(t) \Gamma_{ij}^k(\lambda(t)) \partial_k\\
	&= (V^k)'(t) \partial_k + V^i(t) (\lambda^j)'(t) \Gamma_{ij}^k(\lambda(t)) \partial_k\\
	&= \left((V^k)'(t)  + V^i(t) (\lambda^j)'(t) \Gamma_{ij}^k(\lambda(t))\right) \partial_k.
	\end{align*}
	Pelos termos da equação anterior, mostra-se a unicidade de $D_t$.
	Para mostrar a existência
	seja $(U_{\alpha}, \varphi_{\alpha})$ um atlas de $M$.
	Para cada $U_{\alpha}$ define-se $D_t^{\alpha}$ de maneira similar à prova da unicidade e
	seja $(\psi_{\alpha})$ uma partição da unidade da cobertura $(U_{\alpha})$.
	Usando a partição da unidade define-se
	\begin{equation*}
	D_t = \sum_{\alpha} \psi_{\alpha} D_t^{\alpha}
	\end{equation*}
	Pode-se ver que a aplicação $D_t$, definida anteriormente, cumpre com as propriedades do enunciado.
	Portanto, fica provada a sua existência. 
\end{demonstracao}

\begin{lema}\label{conexao-linear-numa-curva}
	Sejam $M$ uma variedade diferenciável e $p \in M$. Sejam também $X, Y, \tilde{Y} \in \vectorfieldsspace{M}$, $\nabla$ uma conexão linear em $M$, $\gamma: (-\epsilon, \epsilon) \rightarrow M$ uma curva tal que $\gamma(0)=p$ e  $\gamma'(0) = X_p$ e supor que $Y \equiv \tilde{Y}$ na imagem de $\gamma$. Então $\nabla_{X_p} Y = \nabla_{X_p} \tilde{Y}$.
\end{lema}

\begin{demonstracao}
	Estendendo $Y$ e $\tilde{Y}$ a $\vectorfieldsspace{M}$ e usando a propriedade 3 de \ref{derivada-covariante-de-um-caminho} tem-se,
	\begin{align*}
		D_t Y &= \nabla_{\gamma'(t)} Y,\\
		D_t \tilde{Y} &= \nabla_{\gamma'(t)} \tilde{Y}.
	\end{align*}
	Como $Y \equiv \tilde{Y}$ em $\gamma$, então $D_t Y = D_t \tilde{Y}$.
	Portanto $\nabla_{\gamma'(t)} Y = \nabla_{\gamma'(t)} \tilde{Y}$.
	Em particular, para $t=0$,
	\begin{equation*}
		\nabla_{X_p} Y = \nabla_{X_p} \tilde{Y}.
	\end{equation*}
\end{demonstracao}

%\section{Quantas conexões lineares existem?}

\begin{definicao}
	Em $\mathbb{R}^n$, definamos a \emph{conexão Euclideana} $\overline{\nabla}$ como
	\begin{equation*}
		\overline{\nabla}_X \left( Y^j \partial_j \right) = (X Y^j) \partial_j
	\end{equation*}
	onde $X,Y \in \mathfrak{X}(\mathbb{R}^n)$, e $Y = Y^j \partial_j$.
\end{definicao}

\begin{lema}\label{bijecao-entre-a-escolha-dos-simbolos-de-christoffel-e-as-conexoes-lineares}
	Supor que $M$ é uma variedade diferenciável coberta por só uma carta. Existe uma bijeção entre o conjunto das conexões lineares em $M$ e o conjunto das escolhas das $n^3$ funções diferenciáveis $\{ \Gamma^k_{ij} \}$ (símbolos de Christoffel) em $M$, dada por
	\begin{equation*}
		\nabla_X Y = \left( X^i \partial_i Y^k + X^i Y^j \Gamma^k_{ij} \right) \partial_k
	\end{equation*}
\end{lema}

\begin{demonstracao}
	Sejam $X,Y \in \vectorfieldsspace{M}$ e $\{ \partial_i \}$ o referencial local coordenado. Pelo lema \ref{conexiones lineales en función de símbolos de Chritoffel}, tem-se que a conexão linear $\nabla_X Y$ gera um conjunto $\{ \Gamma_{ij}^k \}$ de $n^3$ elementos que são os símbolos de Christoffel. Agora supor que escolhemos un conjunto $\{ \Gamma_{ij}^k \} $ de $n^3$ elementos e definimos o campo vetorial $\nabla_X Y$ como
	\begin{equation*}
		\nabla_X Y = (X Y^k + X^i Y^j \Gamma_{ij}^k) \partial_k.
	\end{equation*}
	Verifica-se que $Y$ é linear em $\realnumbers$ e $X$ é linear em $\smoothfunctionsspace{M}$. Falta provar a regra do produto. Considerar $fY \in \vectorfieldsspace{M}$ em lugar de $Y$ onde $f \in \smoothfunctionsspace{M}$. Então
	\begin{align*}
		\nabla_X (fY) &= (X(f Y^k) + X^i (f Y^j) \Gamma_{ij}^k) \partial_k\\
		&= ( (Xf) Y^k + f X Y^k + f X^i Y^j \Gamma_{ij}^k ) \partial_k\\
		&= (Xf) Y^k \partial_k + f (X Y^k + X^i Y^j \Gamma_{ij}^k) \partial_k\\
		&= (Xf) Y + f \nabla_X Y.
	\end{align*}
\end{demonstracao}

\begin{proposicao}
	Toda variedade diferenciável admite uma conexão linear.
\end{proposicao}

\begin{demonstracao}
	Seja $(U_{\alpha})$ uma cobertura de $M$ e $\nabla^{\alpha}$ a conexão linear em $U_{\alpha}$. Sejam também $(\varphi_{\alpha})$ a partição da unidade subordinada a $(U_{\alpha})$ e $W$ um aberto de $M$ tal que $X,Y \in \vectorfieldsspace{W}$. Definamos
	\begin{equation*}
		\nabla_X Y := \sum_{\alpha} \varphi_{\alpha} \nabla_X^{\alpha} Y.
	\end{equation*}
	$\nabla_X Y$ é uma conexão linear em $M$. Verifica-se que é $\realnumbers$-linear em $Y$ e $\smoothfunctionsspace{M}$-linear em $X$. Tem-se que provar a regra do produto. Considerar $fY \in \vectorfieldsspace{W}$ onde $f \in \smoothfunctionsspace{M}$. Então
	\begin{align*}
		\nabla_X (fY) &= \sum_{\alpha} \varphi_{\alpha} \nabla_X^{\alpha} (fY)\\
		&= \sum_{\alpha} \varphi_{\alpha} (Xf Y + f \nabla_X^{\alpha} Y)\\
		&= \sum_{\alpha} \varphi_{\alpha} X f Y + \sum_{\alpha} \varphi_{\alpha} f \nabla_X^{\alpha} Y. 
	\end{align*}
	Como $(\varphi_{\alpha})$ é partição da unidade, então $\sum_{\alpha} \varphi_{\alpha} = 1$. Portanto, conclui-se que
	\begin{equation*}
		\nabla_X (fY) = X f Y + f \nabla_X Y
	\end{equation*}
	e que $\nabla_X Y$ é uma conexão linear em $M$.
\end{demonstracao}

\section{Geodésicas}

As geodésicas são a generalização dos caminhos retos em um espaço euclideano.
Também são a base da definição de coordenadas normais que serão usada no desenvolvimento da prova da conjectura de Lawson.

\begin{definicao}
	Seja $M$ uma variedade com uma conexão linear $\nabla$ e
	$\lambda$ um caminho em $M$.
	O caminho $\lambda$ é chamado de \emph{geodésica} se $D_t \lambda' \equiv 0$.
\end{definicao}

\begin{teorema}
	Seja $M$ uma variedade com uma conexão linear,
	$p \in M$,
	$v \in T_p M$ e
	$t_0 \in \R$.
	Existe uma intervalo aberto $I \subset \R$ e uma única geodésica $\lambda: I \rightarrow M$ tal que $t_0 \in I$,
	$\lambda(0) = p$ e
	$\lambda'(0) = v$.
\end{teorema}

\begin{demonstracao}
	Ver \cite[Theorem 4.10]{Lee1997}.
\end{demonstracao}

\begin{observacao}
	Seja $M$ uma variedade com uma conexão linear,
	$p \in M$,
	$v \in T_p M$ e
	$\lambda$ uma geodésica em $M$.
	Para remarcar que a geodésica $\lambda$ é gerada por $p$ e $v$ vai-se escrever $\lambda_v$.
\end{observacao}

\begin{definicao}
	Seja $M$ uma variedade riemanniana,
	$p \in M$,
	$V \subset T_p M$ uma vizinhança estrelada de 0,
	$v \in V$, e
	$\lambda_v: [0,1] \rightarrow M$ a geodésica definida por $v$ e $p$.
	A aplicação $\exp_p: V \rightarrow M$ definida
	\begin{equation*}
	\exp_p(v) = \lambda_v(1)
	\end{equation*}
	é chamada de \emph{aplicação exponencial}.
\end{definicao}

\begin{observacao}
	A aplicação exponencial é diferenciável.
\end{observacao}


\section{A conexão riemanniana}

Em esta seção definirá-se a conexão riemanniana, a conexão linear que é simétrica e compatível com a métrica.
Esta conexão origina-se da conexão tangencial da variedade quando é imersa em um espaço euclideano e mostrará-se que esta conexão é única.

\begin{definicao}
	Seja $M \subset \mathbb{R}^n$ uma subvariedade diferenciável. Uma função
	\begin{equation*}
		\nabla^\top: \mathfrak{X}(M) \times \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)
	\end{equation*}
	dada por
	\begin{equation*}
		\nabla^\top_X Y = \pi^\top \left( \overline{\nabla}_X Y \right)
	\end{equation*}
	onde $X,Y \in \mathfrak{X}(M)$ tal que podem ser estendidas como campos em $\mathbb{R}^n$, $\overline{\nabla}$ é a conexão Euclideana em $\mathbb{R}^n$, e para qualquer ponto $p \in M$, $\pi^\top: T_p \mathbb{R}^n \rightarrow T_p M$ é a projeção ortogonal, é chamada de \emph{conexão tangencial}.
\end{definicao}

\begin{lema}\label{boa-definicao-conexao-tangencial}
	O operador $\nabla^\top$ está bem definido, e é uma conexão linear em $M$.
\end{lema}

\begin{demonstracao}
	Para demonstrar a boa definição mostrará-se que independe das extensões dos campos vetoriais em $\realnumbers^n$.
	Sejam $M$ uma subvariedade diferenciável de $\realnumbers^n$, $p \in M$, $\{X,Y\} \subset \vectorfieldsspace{M}$, $\{ \tilde{X}, \hat{X} \}$ extensões de $X$ e $\{ \tilde{Y}, \hat{Y} \}$ extensões de $Y$ em $\realnumbers^n$, e $\gamma: (-\epsilon, \epsilon) \rightarrow M$ uma curva tal que $\gamma(0)=p$, $\gamma'(0)=X_p$ e $\hat{Y} \equiv \tilde{Y}$ em $\gamma$. Tem-se que
	\begin{align*}
		(\pi^\top (\overline{\nabla}_{\hat{X}} \hat{Y}))_p &= \pi^\top ((\overline{\nabla}_{\hat{X}} \hat{Y})_p)\\
		&= \pi^\top (\overline{\nabla}_{\hat{X}_p} \hat{Y})\\
		&= \pi^\top (\overline{\nabla}_{X_p} \hat{Y}).
	\end{align*}
	Pelo lema \ref{conexao-linear-numa-curva}, como $\tilde{Y} \equiv \hat{Y}$ em $\gamma$, então
	\begin{align*}
		(\pi^\top (\overline{\nabla}_{\hat{X}} \hat{Y}))_p &= \pi^\top (\overline{\nabla}_{X_p} \tilde{Y})\\
		&= \pi^\top (\overline{\nabla}_{\tilde{X}_p} \tilde{Y})\\
		&= (\pi^\top (\overline{\nabla}_{\tilde{X}} \tilde{Y}))_p.
	\end{align*}
	Agora, sejam $X,Y,W,Z \in \vectorfieldsspace{M}$, $a \in \realnumbers$ e $f \in \smoothfunctionsspace{M}$. Tem-se que $\tangentialconnection$ cumpre
	\begin{align*}
		\nabla^\top_X (aY + Z) &= \pi^\top (\overline{\nabla}_X (aY+Z))\\
		&= \pi^\top (a \overline{\nabla}_X Y + \overline{\nabla}_X Z)\\
		&= a \pi^\top (\overline{\nabla}_X Y) + \pi^\top (\overline{\nabla}_X Z)\\
		&= a \nabla^\top_X Y + \nabla^\top_X Z
	\end{align*}
	e
	\begin{align*}
		\nabla^\top_{fX + W} Y &= \pi^\top (\euclideanconnection_{fX + W} Y)\\
		&= \pi^\top (f \euclideanconnection_X Y + \euclideanconnection_W Y)\\
		&= f \pi^\top (\euclideanconnection_X Y) + \pi^\top (\euclideanconnection_W Y)\\
		&= f \tangentialconnection_X Y + \tangentialconnection_W Y.
	\end{align*}
	Portanto, $\tangentialconnection$ é uma conexão linear.
\end{demonstracao}

\begin{teorema}[John Nash]
	Qualquer métrica riemanniana em uma variedade pode-se considerar como a métrica induzida em algum espaço Euclideano.
\end{teorema}

\begin{demonstracao}
	Ver \cite[Theorem 3]{Nash1956}.
\end{demonstracao}

\begin{proposicao}
	Seja $M$ uma variedade riemanniana e
	$\nabla$ uma conexão linear de $M$.
	$\nabla$ é chamada de \emph{compatível com a métrica de $M$} se satisfaz a regra:
	\begin{equation*}
		X \langle Y,Z \rangle = \langle \nabla_X Y, Z \rangle + \langle Y, \nabla_X Z \rangle
	\end{equation*}
	onde $X,Y,Z \in \mathfrak{X}(M)$.
\end{proposicao}

\begin{demonstracao}
	Ver \cite[Cap. 2, corolário 3.3]{Carmo1988}.
\end{demonstracao}

%\begin{definicao}
%	O \emph{tensor de torção da conexão} é uma aplicação $\tau: \mathfrak{X}(M) \times \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)$ definida por
%	\begin{equation*}
%		\tau(X,Y) = \nabla_X Y - \nabla_Y X - [X,Y].
%	\end{equation*}
%\end{definicao}

\begin{definicao}
	Uma conexão linear é chamada de \emph{simétrica} se
	\begin{equation*}
		\nabla_X Y - \nabla_Y X = [X,Y].
	\end{equation*}
\end{definicao}

\begin{lema}\label{conexao-tangencial-simetrica}
	A conexão tangencial numa variedade mergulhada $M \subset \realnumbers^n$ é simétrica.
\end{lema}

\begin{demonstracao}
	Sejam $X$ e $Y$ elementos de $\vectorfieldsspace{M}$, $\tilde{X}$ e $\tilde{Y}$ elementos de $\vectorfieldsspace{\realnumbers^n}$ tal que são extensões de $X$ e $Y$, e $\{ \partial_i \}$ o referencial local coordenado em $\realnumbers^n$. Tem-se que $\tilde{X} = \tilde{X}^i \partial_i$ e $\tilde{Y} = \tilde{Y}^j \partial_j$, onde os $\tilde{X}^i$, $\tilde{Y}^j$ estão em $\smoothfunctionsspace{\realnumbers^n}$. Então,
	\begin{align*}
		\tangentialconnection_X Y &= \pi^\top (\euclideanconnection_{\tilde{X}} \tilde{Y})\\
		&= \pi^\top (\euclideanconnection_{\tilde{X}^i \partial_i} (\tilde{Y}^j \partial_j))\\
		&= \pi^\top (\tilde{X}^i \euclideanconnection_{\partial_i} (\tilde{Y}^j \partial_j))\\
		&= \pi^\top (\tilde{X}^i \partial_i \tilde{Y}^j \partial_j)\\
		&= \pi^\top (\tilde{X} \tilde{Y})\\
		&= XY.
	\end{align*}
	De maneira similar,
	\begin{equation*}
		\tangentialconnection_Y X = YX.
	\end{equation*}
	Por tanto $ \tangentialconnection_X Y - \tangentialconnection_Y X \equiv [X,Y] $ e conclui-se que $\tangentialconnection$ é simétrica.
\end{demonstracao}

%\begin{definicao}
%	\begin{equation*}
%	(\nabla g)(X,Y,Z) := (\nabla_Z g)(X,Y)
%	\end{equation*}
%\end{definicao}

%\begin{lema}\label{compatibilidade-duma-conexao-riemanniana-com-uma-metrica-usando-a-derivada-covariante}
%	$\nabla$ é compatível com $g$, se e somente se, $\nabla g \equiv 0$.
%\end{lema}

%\begin{lema}\label{deriva-covariante-de-uma-metrica}
%	\begin{equation*}
%	(\nabla g)(X,Y,Z) = Z(g(X,Y)) - g(\nabla_Z X, Y) - g(X, \nabla_Z Y)
%	\end{equation*}
%\end{lema}

\begin{teorema}\label{conexao-riemanniana}
	Seja $(M,g)$ uma variedade riemanniana. Existe uma única conexão linear $\nabla$ em $M$ que é compatível com $g$ e é simétrica.
	Esta conexão é chamada de \emph{conexão riemanniana} o de \emph{conexão de Levi-Civita} de $g$.
\end{teorema}

A demonstração de este teorema vai-se dividir em os 3 lemas seguintes.

\begin{lema}\label{conexao-riemanniana-lema-1}
	Assumindo que existe conexão linear do Teorema \ref{conexao-riemanniana}, esta é única.
\end{lema}

\begin{demonstracao}
	Sejam $\nabla$ a conexão linear do Teorema \ref{conexao-riemanniana}, e $X,Y,Z$ campos vetoriais em $M$. Então,
	\begin{align*}
		X \innerproduct{Y}{Z} &= \innerproduct{\nabla_X Y}{Z} + \innerproduct{Y}{\nabla_X Z}\\
		Y \innerproduct{Z}{X} &= \innerproduct{\nabla_Y Z}{X} + \innerproduct{Z}{\nabla_Y X}\\
		Z \innerproduct{X}{Y} &= \innerproduct{\nabla_Z X}{Y} + \innerproduct{X}{\nabla_Z Y}.
	\end{align*}
	Usando o fato que $\nabla$ é simétrica tem-se que
	\begin{align*}
	X \innerproduct{Y}{Z} &= \innerproduct{\nabla_X Y}{Z} + \innerproduct{Y}{\nabla_Z X} + \innerproduct{Y}{\liebrackets{X}{Z}}\\
	Y \innerproduct{Z}{X} &= \innerproduct{\nabla_Y Z}{X} + \innerproduct{Z}{\nabla_X Y} + \innerproduct{Z}{\liebrackets{Y}{X}}\\
	Z \innerproduct{X}{Y} &= \innerproduct{\nabla_Z X}{Y} + \innerproduct{X}{\nabla_Y Z} + \innerproduct{X}{\liebrackets{Z}{Y}}.
	\end{align*}
	Somando a dois primeiras equações e restando a terceira obtê-se que
	\begin{equation*}
		X \innerproduct{Y}{Z} + Y \innerproduct{Z}{X} - Z \innerproduct{X}{Y} = 2 \innerproduct{\nabla_X Y}{Z} + \innerproduct{Y}{\liebrackets{X}{Z}} + \innerproduct{Z}{\liebrackets{Y}{X}} - \innerproduct{X}{\liebrackets{Z}{Y}}.
	\end{equation*}
	Afinal, $\innerproduct{\nabla_X Y}{Z}$ fica definido por
	\begin{equation}\label{eq:conexao-riemanniana-lema-1-eq-a}
		\innerproduct{\nabla_X Y}{Z} = \frac{1}{2} ( X \innerproduct{Y}{Z} + Y \innerproduct{Z}{X} - Z \innerproduct{X}{Y} - \innerproduct{Y}{\liebrackets{X}{Z}} - \innerproduct{Z}{\liebrackets{Y}{X}} + \innerproduct{X}{\liebrackets{Z}{Y}} ).
	\end{equation}
	Seja $\tilde{\nabla}$ outra conexão linear. Fazendo o mesmo procedimento, $\innerproduct{\tilde{\nabla}_X Y}{Z}$ fica definido também por
	\begin{equation*}
	\innerproduct{\tilde{\nabla}_X Y}{Z} = \frac{1}{2} ( X \innerproduct{Y}{Z} + Y \innerproduct{Z}{X} - Z \innerproduct{X}{Y} - \innerproduct{Y}{\liebrackets{X}{Z}} - \innerproduct{Z}{\liebrackets{Y}{X}} + \innerproduct{X}{\liebrackets{Z}{Y}} ).
	\end{equation*}
	Como $X,Y,Z \in \vectorfieldsspace{M}$ são arbitrários e $ \innerproduct{\nabla_X Y - \tilde{\nabla}_X Y}{Z} = 0 $, conclui-se que $ \nabla = \tilde{\nabla} $.
\end{demonstracao}

\begin{lema}\label{conexao-riemanniana-lema-2}
	A conexão linear do Teorema \ref{conexao-riemanniana} existe.
\end{lema}

\begin{demonstracao}
	Sejam
	$\{ (U_{\alpha}, \varphi_{\alpha}) \}$ um atlas de $M$ e
	$\{ \partial_m \}$ o referencial local coordenado em $U_{\alpha}$ para algum $\alpha$.
	Pela equação \eqref{eq:conexao-riemanniana-lema-1-eq-a} tem-se
	\begin{equation}\label{eq:conexao-riemanniana-lema-2-eq-b}
		\begin{split}
			\innerproduct{\nabla_{\partial_i} \partial_j}{\partial_k} &= \frac{1}{2} (\partial_i \innerproduct{\partial_j}{\partial_k} + \partial_j \innerproduct{\partial_k}{\partial_i} - \partial_k \innerproduct{\partial_i}{\partial_j})\\
			\innerproduct{\Gamma_{ij}^l \partial_l}{\partial_k} &= \frac{1}{2} (\partial_i \innerproduct{\partial_j}{\partial_k} + \partial_j \innerproduct{\partial_k}{\partial_i} - \partial_k \innerproduct{\partial_i}{\partial_j}).		
		\end{split}		
	\end{equation}
	Como $g_{ij} = \innerproduct{\partial_i}{\partial_j}$, então a equação \eqref{eq:conexao-riemanniana-lema-2-eq-b} fica
	\begin{equation}\label{eq:conexao-riemanniana-lema-2-eq-a}
		\Gamma_{ij}^l g_{lk} = \frac{1}{2} (\partial_i g_{jk} + \partial_j g_{ki} - \partial_k g_{ij}).
	\end{equation}
	Multiplicando por $g^{kl}$, onde $g^{kl}$ é elemento da matriz $[g^{kl}]$ que é a matriz inversa de $[g_{lk}]$, obtê-se
	\begin{equation*}
		\Gamma_{ij}^l = \frac{1}{2} (\partial_i g_{jk} + \partial_j g_{ki} - \partial_k g_{ij}) g^{kl}.
	\end{equation*}
	Então, tendo uma escolha de símbolos de Christoffel $\{ \Gamma_{ij}^l \}$, pelo Lema \ref{bijecao-entre-a-escolha-dos-simbolos-de-christoffel-e-as-conexoes-lineares}, existe uma conexão linear $\nabla^{\alpha}$.
	A partir dos $\nabla^{\alpha}$ podemos obter uma conexão linear $\nabla$ para $M$ usando a partição da unidade.
\end{demonstracao}

\begin{lema}\label{conexao-riemanniana-lema-3}
	A conexão linear do Teorema \ref{conexao-riemanniana} é compatível com a métrica.
\end{lema}

\begin{demonstracao}
%	Pelo Lema \ref{compatibilidade-duma-conexao-riemanniana-com-uma-metrica-usando-a-derivada-covariante} basta com provar que $\nabla g \equiv 0$.
	Seja
	$(U_{\alpha})$ uma cobertura de $M$ e 
	$\{ \partial_m \}$ um referencial em $U_{\alpha}$ para algum $\alpha$.
	Basta provar
%	Pelo Lema \ref{deriva-covariante-de-uma-metrica} tem-se
%	\begin{equation}\label{eq:conexao-riemanniana-lema-3-eq-a}
%		\begin{split}
%			(\nabla g) (\partial_i, \partial_j, \partial_k) &= \partial_k g(\partial_i, \partial_j) - g(\nabla_{\partial_k} \partial_i, \partial_j) - g(\partial_i, \nabla_{\partial_k} \partial_j)\\
%			&= \partial_k g_{ij} - \Gamma_{ki}^l g_{lj} - \Gamma_{kj}^l g_{il}.
%		\end{split}	
%	\end{equation}
	\begin{equation*}
		\partial_k \innerproduct{\partial_i}{\partial_j} = \innerproduct{\nabla_{\partial_k} \partial_i}{\partial_j} + \innerproduct{\partial_i}{\nabla_{\partial_k} \partial_j},
	\end{equation*}
	e isto é equivalente a provar
	\begin{equation*}
		\partial_k g_{ij} = \Gamma_{ki}^l g_{lj} + \Gamma_{kj}^l g_{li}.
	\end{equation*}
	Usando a equação \eqref{eq:conexao-riemanniana-lema-2-eq-a} tem-se
	\begin{align*}
	\Gamma_{ki}^l g_{lj} + \Gamma_{kj}^l g_{li} &= \frac{1}{2} (\partial_k g_{ij} + \partial_i g_{jk} - \partial_j g_{ki}) + \frac{1}{2} (\partial_k g_{ji} + \partial_j g_{ik} - \partial_i g_{kj})\\
	&= \partial_k g_{ij}.
	\end{align*}
%	Então,
%	\begin{equation*}
%	(\nabla g) (\partial_i, \partial_j, \partial_k) = 0.
%	\end{equation*}
	Portanto, a conexão linear é compatível com a métrica.
\end{demonstracao}

\begin{demonstracao}[do teorema \ref{conexao-riemanniana}]
	Usando \ref{conexao-riemanniana-lema-1}, \ref{conexao-riemanniana-lema-2} e \ref{conexao-riemanniana-lema-3}, chega-se à conclusão.
\end{demonstracao}


\begin{proposicao}\label{conexao-pullback}
	Sejam $(M,g)$ e $(\tilde{M}, \tilde{g})$ variedades riemannianas, $\nabla$ e $\tilde{\nabla}$ as conexões Levi-Civita de $M$ e $\tilde{M}$ respetivamente, e $F: (M,g) \rightarrow (\tilde{M},\tilde{g})$ uma função diferenciável. A função
	\begin{equation*}
	F^* \tilde{\nabla}: \mathfrak{X}(M) \times \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)
	\end{equation*}
	definida por
	\begin{equation*}
	\left( F^* \tilde{\nabla} \right)_X Y = F^{-1}_* \left( \tilde{\nabla}_{F_* X} (F_* Y) \right)
	\end{equation*}
	onde $X,Y \in \mathfrak{X}(M)$ descreve uma conexão em $M$ chamada de \emph{conexão pullback} que é simétrica e compatível com $g$. Portanto, pela unicidade da conexão Levi-Civita, $F^* \tilde{\nabla} = \nabla$.
\end{proposicao}

\begin{demonstracao}
	$(F^* \tilde{\nabla})$ é simétrica, porque
	\begin{align*}
		\left(F^* \tilde{\nabla}\right)_X Y - \left(F^* \tilde{\nabla}\right)_Y X &= F_*^{-1} \left(\tilde{\nabla}_{F_* X} F_*Y\right) - F_*^{-1} \left(\tilde{\nabla}_{F_* Y} F_* X\right)\\
		&= F_* ^{-1} \left(\tilde{\nabla}_{F_* X} F_*Y - \tilde{\nabla}_{F_* Y} F_* X\right)\\
		&= F_*^{-1} \left[F_*X, F_*Y\right].
	\end{align*}
	Usando \cite[Corollary 8.31]{Lee2012},
	\begin{equation*}
		\left(F^* \tilde{\nabla}\right)_X Y - \left(F^* \tilde{\nabla}\right)_Y X * = [X,Y].
	\end{equation*}
	Também tem-se que $(F^* \tilde{\nabla})$ é compatível com a métrica, porque, usando
	\begin{equation*}
		\innerproduct{Y}{Z} = \innerproduct{F_* Y}{F_* Z} \circ F		
	\end{equation*}
	consegue-se
	\begin{align*}
		X \innerproduct{Y}{Z} &= X \left(\innerproduct{F_* Y}{F_* Z} \circ F\right)\\
		&= \left(F_* X \innerproduct{F_* Y}{F_* Z}\right) \circ F\\
		&= \left(\innerproduct{\tilde{\nabla}_{F_* X} F_* Y}{F_* Z} + \innerproduct{F_* Y}{\tilde{\nabla}_{F_* X} F_* Z}\right) \circ F\\
		&= \innerproduct{F_*^{-1} \tilde{\nabla}_{F_* X} F_* Y}{Z} + \innerproduct{Y}{F_*^{-1} \tilde{\nabla}_{F_* X} F_* Z}\\
		&= \innerproduct{\left(F^* \tilde{\nabla}\right)_X Y}{Z} + \innerproduct{Y}{\left(F^* \tilde{\nabla}\right)_X Z}.
	\end{align*}
	Então, $(F^* \tilde{\nabla})$ é uma conexão linear simétrica compatível com a métrica. Portanto, pela unicidade da conexão riemanniana, $F^* \tilde{\nabla} = \nabla$.
\end{demonstracao}

\begin{proposicao}
	Supor que $F: (M,g) \rightarrow (\tilde{M}, \tilde{g})$ é uma isometria, então $F$ leva a conexão riemanniana $\nabla$ de $g$ à conexão riemanniana de $\tilde{\nabla}$ de $\tilde{g}$ com a regra:
	\begin{equation*}
		F_* (\nabla_X Y) = \tilde{\nabla}_{F_* X} (F_* Y)
	\end{equation*}
\end{proposicao}

\begin{demonstracao}
	Pela proposição \ref{conexao-pullback}, 
	\begin{equation*}
		\nabla_X Y = F^{-1}_* \left( \tilde{\nabla}_{F_* X} (F_* Y) \right).
	\end{equation*}
	Portanto,
	\begin{equation*}
		F_* (\nabla_X Y) = \tilde{\nabla}_{F_* X} (F_* Y).
	\end{equation*}
\end{demonstracao}

\begin{definicao}
	Seja $M$ uma variedade diferenciável e
	$\lambda: I \rightarrow M$ um caminho.
	Um \emph{campo vetorial ao longo do caminho} $\lambda$ é uma aplicação diferenciável $V: I \rightarrow TM$ tal que $V(t) \in T_{\lambda(t)} M$.
	Um espaço de campos vetoriais ao longo do caminho $\lambda$ é denotado por $\vectorfieldsspace{\lambda}$.
\end{definicao}



\section{Coordenadas normais geodésicas}

Em esta seção apresentarão-se os conceitos que serão usados no desenvolvimento da prova da conjectura de Lawson no capítulo principal.

\begin{lema}\label{lema:vizinhanca-normal}
	Seja
	$M$ uma variedade riemanniana,
	$p \in M$.
	Então, existe uma vizinhança $V$ do origem em $T_p M$ e uma vizinhança $U$ de $p$ em $M$ tal que $\exp_p: V \rightarrow U$ é um difeomorfismo.
\end{lema}

\begin{demonstracao}
	Ver \cite[Lemma 5.10]{Lee1997}.
\end{demonstracao}

\begin{definicao}
	A vizinhança $U$ no lema \ref{lema:vizinhanca-normal} é chamada de \emph{vizinhança normal de $p$}.
	Seja
	$\epsilon > 0$ e
	$B_{\epsilon}(0) \subset T_p M$ tal que $\exp_p$ é um difeomorfismo em $B_{\epsilon}(0)$.
	Então,
	$\exp_p(B_{\epsilon}(0))$ é chamada de \emph{bola geodésica em $M$} e
	$\exp_p(\overline{B}_{\epsilon}(0))$ é chamada de \emph{bola geodésica fechada em $M$}.
\end{definicao}

\begin{definicao}
	Seja
	$M$ uma variedade riemanniana,
	$p \in M$,
	$U$ uma vizinhança normal de $p$,
	$\{v_i\}$ uma base ortonormal de $T_p M$ e
	$E: \R^n \rightarrow T_p M$ um isomorfismo tal que $E(x^1,\ldots,x^n) = x^i v^i$.
	Então,
	\begin{equation*}
		\varphi := E^{-1} \circ \exp_p^{-1}: U \rightarrow \R^n
	\end{equation*}
	é chamada de \emph{coordenadas normais geodésicas}.
\end{definicao}

\section{Curvatura}

Nesta seção apresentará-se a generalização do conceito de curvatura às variedades riemannianas.
Definirão-se o endomorfismo de curvatura e o tensor de curvatura que serão usados posteriormente e mostrará-se as suas propriedades.


\begin{definicao}
	Se $M$ é uma variedade riemanniana, o \emph{endomorfismo de curvatura} é a função $R: \vectorfieldsspace{M} \times \vectorfieldsspace{M} \times \vectorfieldsspace{M} \rightarrow \vectorfieldsspace{M} $ definido por
	\begin{equation*}
		R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z.
	\end{equation*}
\end{definicao}

%\begin{proposicao}
%	O endomorfismo de curvatura é um campo tensorial $\binom{3}{1}$.
%\end{proposicao}

\begin{definicao}
	O \emph{tensor de curvatura} é a aplicação $R_m: \vectorfieldsspace{M}^4 \rightarrow \smoothfunctionsspace{M}$ definida por
	\begin{equation*}
		R_m (X,Y,Z,W) = \langle R(X,Y)Z,W \rangle
	\end{equation*}
\end{definicao}

\begin{teorema}
	O endomorfismo de curvatura e o tensor de curvatura são invariantes isométricos locais.
\end{teorema}

\begin{demonstracao}
	Sejam $M$ e $\tilde{M}$ $n$-variedades riemannianas,
	$\nabla$ e $\tilde{\nabla}$ as conexões riemannianas de $M$ e $\tilde{M}$,
	$R$ e $\tilde{R}$ os endomorfismos de curvatura de $M$ e $\tilde{M}$,
	$R_m$ e $\tilde{R}_m$ as tensores de curvatura de $M$ e $\tilde{M}$ ,
	$p \in M$,
	$U$ aberto de $M$ tal que $p \in U$;
	$X,Y,Z,W \in \vectorfieldsspace{U}$,
	$f: M \rightarrow \tilde{M}$ uma isometria local e
	$f_*$ o pushforward de $f$ em $\vectorfieldsspace{M}$.
	Então, pode-ser ver que
	\begin{align*}
		\tilde{R}(f_*X, f_*Y)f_*Z &= \tilde{\nabla}_{f_*X} \tilde{\nabla} f_*Y f_*Z - \tilde{\nabla}_{f_*Y} \tilde{\nabla}_{f_*X} f_*Z - \tilde{\nabla}_{[f_*X, f_*Y]} f_*Z\\
		&= f_* \left(\nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z\right)\\
		&= f_* R(X,Y)Z
	\end{align*}
	e
	\begin{align*}
		\tilde{R}_m(f_*X, f_*Y, f_*Z, f_*W)
		&= \innerproduct{\tilde{R}(f_*X, f_*Y)f_*Z}{f_*W}\\
		&= \innerproduct{f_* R(X,Y)Z}{f_*W}\\
		&= \innerproduct{R(X,Y)Z}{W}\\
		&= R_m(X,Y,Z,W).
	\end{align*}
	Portanto, o endomorfismo de curvatura e o tensor de curvatura são invariantes isométricos locais.
\end{demonstracao}

%\section{Quê mede o tensor de curvatura?}

Em os seguintes resultados mostrará-se que o tensor de curvatura mede como uma variedade riemanniana afasta-se da propriedade de ser euclideano, i.e., ser ``plano''.

\begin{definicao}
	Seja $M$ uma variedade riemanniana.
	$M$ é chamada de \emph{flat} se é localmente isométrica a um espaço euclideano.
\end{definicao}

\begin{teorema}
	Uma variedade riemanniana é flat se e somente se o tensor de curvatura é identicamente nulo.
\end{teorema}

\begin{demonstracao}
	Ver \cite[Theorem 7.3]{Lee1997}.
\end{demonstracao}


%\section{Propriedades do tensor de curvatura}

\begin{proposicao}\label{simetrias-del-tensor-de-curvatura}
	O tensor de curvatura tem as seguentes simetrias para qualquer campo vetorial $X,Y,Z,W$:
	\begin{enumerate}
		\item $R_m(W,X,Y,Z) = -R_m(X,W,Y,Z)$.
		\item $R_m(W,X,Y,Z) = -R_m(W,X,Z,Y)$.
		\item $R_m(W,X,Y,Z) = -R_m(Y,Z,W,X)$.
		\item $R_m(W,X,Y,Z) + R_m(X,Y,W,Z) + R_m(Y,W,X,Z) = 0$.
	\end{enumerate}
\end{proposicao}

\begin{demonstracao}
	Ver \cite[Proposition 7.4]{Lee1997}.
\end{demonstracao}








\section{Subvariedades riemannianas}

Nesta seção apresentará-se os resultados da teoria de subvariedades riemannianas de forma geral.
Posteriormente obterá-se resultados para o caso específico onde a subvariedade tem codimensão 1.

\begin{observacao}
	Se $(M,g)$ é uma variedade riemanniana, toda subvariedade $S \subset M$, imersa o mergulhada, automaticamente herda a métrica pullback $i^* g$, onde $i: S \rightarrow M$ é a função inclusão.
\end{observacao}

\begin{definicao}\label{metrica_induzida}
	A métrica pullback sobre a subvariedade de uma variedade riemanniana é chamada de \emph{métrica induzida}.
\end{definicao}

\begin{observacao}
	Pela definição \ref{metrica_pullback}, seja $v,w \in T_p S$ tal que
	\begin{equation*}
	(i^* g)(v,w) = g(di_p v, di_p w) = g(v,w). 
	\end{equation*}
	Portanto, $i^* g$ é a restrição de $g$ a um par de vetores tangentes a $S$. 
\end{observacao}



\begin{definicao}
	Seja $(M,g)$ uma variedade riemanniana e $S \subset M$ uma subvariedade imersa o mergulhada com a métrica induzida, é chamada de \emph{subvariedade riemanniana} de $M$.
\end{definicao}

\begin{observacao}
	Seja $M$ uma subvariedade riemanniana de $\tilde{M}$,
	$\tilde{\nabla}$ a conexão riemanniana de $\tilde{M}$ e 
	$X,Y \in \vectorfieldsspace{M}$ que são estendidos a $\vectorfieldsspace{\tilde{M}}$ para que $\tilde{\nabla}_X Y$ esteja bem definida.
	Então, $\tilde{\nabla}_X Y$ pode-se escreve
	\begin{equation*}
	\tilde{\nabla}_X Y = \left(\tilde{\nabla}_X Y\right)^\top + \left(\tilde{\nabla}_X Y\right)^\perp,
	\end{equation*}
	onde $\left(\tilde{\nabla}_X Y\right)^\top$ é a projeção tangencial a $M$ e $\left(\tilde{\nabla}_X Y\right)^\perp$ é a projeção ortogonal a $M$.
\end{observacao}
%\section{A equação de Gauss}

\begin{definicao}
	Seja $M$ uma subvariedade riemanniana de $\tilde{M}$,
	$\tilde{\nabla}$ é a conexão riemanniana $\tilde{M}$ e
	$X,Y \in \vectorfieldsspace{M}$ estendidos a $\vectorfieldsspace{\tilde{M}}$.
	A aplicação $\alpha: \vectorfieldsspace{M} \times \vectorfieldsspace{M} \rightarrow \vectorfieldsspace{M}^\perp$ dada por
	\begin{equation*}
		\alpha(X,Y) = (\tilde{\nabla}_X Y)^\perp
	\end{equation*} 
	é chamada de \emph{segunda forma fundamental}.
\end{definicao}

\begin{proposicao}
	A segunda forma fundamental é
	\begin{enumerate}
		\item independente das extensões $X$ e $Y$;
		\item bilinear sobre $\smoothfunctionsspace{M}$; e
		\item simétrico em $X$ e $Y$.
	\end{enumerate}
\end{proposicao}

\begin{demonstracao}
	As propriedade são consequência direta das propriedades de $\tilde{\nabla}$ e a linearidade do operador linear $\perp$. 
\end{demonstracao}

\begin{teorema}[A Fórmula de Gauss]\label{formula-de-gauss},
	Seja $M$ uma subvariedade riemanniana de $\tilde{M}$,
	$\tilde{\nabla}, \nabla$ as conexões riemannianas de $\tilde{M}$ e $M$ respectivamente e
	$X,Y \in \vectorfieldsspace{M}$ tal que são estendidos arbitrariamente a campos vetoriais de $\tilde{M}$.
	Então, a seguente fórmula cumpre-se em $M$:
	\begin{equation*}
		\tilde{\nabla}_X Y = \nabla_X Y + \alpha(X,Y).
	\end{equation*}
\end{teorema}

\begin{demonstracao}
	Basta com provar que $\left(\tilde{\nabla}_X Y\right)^\top = \nabla_X Y$. 
	Seja $\tangentialconnection: \vectorfieldsspace{M} \rightarrow \vectorfieldsspace{M}$ definido por
	\begin{equation*}
		\tangentialconnection_X Y = \left(\tilde{\nabla}_X Y\right)^\top	
	\end{equation*}
	Pode-se provar que $\tangentialconnection$, usando um procedimento similar na prova do lema \ref{boa-definicao-conexao-tangencial} e do lema \ref{conexao-tangencial-simetrica}, que é uma conexão linear simétrica de $M$. Para provar que $\tangentialconnection$ é compatível com a métrica basta ver que para $X,Y \in \vectorfieldsspace{M}$ estendidos a $\vectorfieldsspace{\tilde{M}}$ tem-se
	\begin{align*}
		Z \innerproduct{X}{Y} &= \innerproduct{\tilde{\nabla}_Z X}{Y} + \innerproduct{X}{\tilde{\nabla}_Z Y}\\
		&= \innerproduct{\tangentialconnection_Z X}{Y} + \innerproduct{X}{\tangentialconnection_Z Y}.
	\end{align*}
	Portanto, $\tangentialconnection$ é a conexão riemanniana de $M$ e, pela unicidade da conexão riemanniana, $\tangentialconnection = \nabla$.
\end{demonstracao}

\begin{proposicao}[A fórmula de Gauss para caminhos]\label{formula-de-gauss-para-caminhos}
	Seja $M$ uma subvariedade riemanniana de $\tilde{M}$, e $\gamma$ um caminho em $M$. Para $X \in \vectorfieldsspace{\gamma}$,
	\begin{equation*}
	\tilde{D}_t X = D_t X + \alpha(\gamma', X).
	\end{equation*}
\end{proposicao}

\begin{demonstracao}
	Seja $\{\partial_1, \ldots, \partial_n \}$ um referencial ortonormal de $M$. Então, $X$ escreve-se
	\begin{equation*}
	X(t) = X^i(t) \partial_i.
	\end{equation*}
	Pela construção em a demonstração da proposição \ref{derivada-covariante-de-um-caminho}, tem-se
	\begin{equation*}
	\tilde{D}_t X = (X^i)' \partial_i + X^i \tilde{\nabla}_{\gamma'} \partial_i.
	\end{equation*}
	Usando a fórmula de Gauss (teorema \ref{formula-de-gauss}),
	\begin{equation*}
	\tilde{D}_t X = (X^i)' \partial_i + X^i \nabla_{\gamma'} \partial_i + X^i \alpha(\gamma', \partial_i).
	\end{equation*}
	Usando a linearidade da conexão $\nabla$ em $\nabla_{\gamma'} \partial_i$,
	\begin{align*}
	\tilde{D}_t X &= (X^i)' \partial_i + X^i (\gamma^j)' \nabla_{\partial_j} \partial_i + \alpha(\gamma', X^i \partial_i),\\
	\tilde{D}_t X &= (X^k)' \partial_k + X^i (\gamma^j)' \Gamma_{ji}^k \partial_k + \alpha(\gamma', X),\\
	\tilde{D}_t X &=  \left((X^k)' + X^i (\gamma^j)' \Gamma_{ji}^k\right) \partial_k + \alpha(\gamma', X).
	\end{align*}
	Como $D_t X = \left((X^k)' + X^i (\gamma^j)' \Gamma_{ji}^k\right) \partial_k$ então
	\begin{equation*}
	\tilde{D}_t X = D_t X + \alpha(\gamma',X).
	\end{equation*}
\end{demonstracao}

\begin{lema}[A Equação de Weingarten]\label{equacao-de-weingarten}
	Supor que $X,Y \in \vectorfieldsspace{M}$ e $N \in \vectorfieldsspace{M}^\perp$. Quando $X,Y,N$ são estendidos a $\tilde{M}$, cumpre-se a seguente equação:
	\begin{equation*}
		\innerproduct{\tilde{\nabla}_X N}{Y} = -\innerproduct{N}{\alpha(X,Y)}.
	\end{equation*}
\end{lema}

\begin{demonstracao}
	Como $Y \perp N$,
	\begin{equation*}
		X \innerproduct{Y}{N} = 0.
	\end{equation*}
	Desenvolvendo a igualdade anterior,
	\begin{equation*}
		\innerproduct{\tilde{\nabla}_X Y}{N} + \innerproduct{Y}{\tilde{\nabla}_X N} = 0.
	\end{equation*}
	Então,
	\begin{equation*}
		\innerproduct{\tilde{\nabla}_X N}{Y} = -\innerproduct{N}{\tilde{\nabla}_X Y}.
	\end{equation*}
	Pela fórmula de Gauss (teorema \ref{formula-de-gauss}),
	\begin{equation*}
		\innerproduct{\tilde{\nabla}_X N}{Y} = - \innerproduct{N}{\nabla_X Y + \alpha(X,Y)}.
	\end{equation*}
	Portanto, pelo fato que $N \perp \nabla_X Y$, a igualdade anterior escreve-se
	\begin{equation*}
		\innerproduct{\tilde{\nabla}_X N}{Y} = - \innerproduct{N}{\alpha(X,Y)}
	\end{equation*}
\end{demonstracao}

\begin{teorema}[A Equação de Gauss]\label{equacao-de-gauss}
	Seja $M$ uma subvariedade de $\tilde{M}$;
	$X,Y,Z,W \in \vectorfieldsspace{M}$,
	$\tilde{R}_m, R_m$ os tensores de curvatura de $M$ e $\tilde{M}$ respectivamente e
	$\alpha$ a segunda forma fundamental de $M$.
	Então, cumpre-se o seguente:
	\begin{equation*}
		\tilde{R}_m(X,Y,Z,W) = R_m(X,Y,Z,W) - \innerproduct{\alpha(X,W)}{\alpha(Y,Z)} + \innerproduct{\alpha(X,Z)}{\alpha(Y,W)}.
	\end{equation*}
\end{teorema}

\begin{demonstracao}
	Pelas definições do tensor de curvatura e do endomorfismo de curvatura,
	\begin{align*}
		\tilde{R}_m(X,Y,Z,W) &= \innerproduct{\tilde{R}(X,Y)Z}{W}\\
		&= \innerproduct{\tilde{\nabla}_X \tilde{\nabla}_Y Z - \tilde{\nabla}_Y \tilde{\nabla}_X Z - \tilde{\nabla}_{[X,Y]} Z}{W}.
	\end{align*}
	Usando a fórmula de Gauss (teorema \ref{formula-de-gauss}),
	\begin{align*}
		\tilde{R}_m(X,Y,Z,W) &= \innerproduct{\tilde{\nabla}_X (\nabla_Y Z + \alpha(Y,Z)) - \tilde{\nabla}_Y (\nabla_X Z + \alpha(X,Z)) - \nabla_{[X,Y]} Z - \alpha([X,Y],Z)}{W}\\
		&= \innerproduct{\tilde{\nabla}_X \nabla_Y Z + \tilde{\nabla}_X \alpha(Y,Z) - \tilde{\nabla}_Y \nabla_X Z - \tilde{\nabla}_Y \alpha(X,Z) - \nabla_{[X,Y]} Z - \alpha([X,Y],Z)}{W}.
	\end{align*}
	Como $\alpha([X,Y],Z) \perp W$,
	\begin{align*}
		\tilde{R}_m(X,Y,Z,W) &= \innerproduct{\tilde{\nabla}_X \nabla_Y Z + \tilde{\nabla}_X \alpha(Y,Z) - \tilde{\nabla}_Y \nabla_X Z - \tilde{\nabla}_Y \alpha(X,Z) - \nabla_{[X,Y]} Z}{W}\\
		&= \left\langle \nabla_X \nabla_Y Z + \alpha(X, \nabla_Y Z) + \tilde{\nabla}_X \alpha(Y,Z) - \nabla_Y \nabla_X Z - \alpha(Y, \nabla_X Z) - \tilde{\nabla}_Y \alpha(X,Z)\right.\\
		& \left. - \nabla_{[X,Y]} Z, W \right\rangle.
	\end{align*}
	Pelo fato que $\alpha(X, \nabla_Y Z)$ e $\alpha(Y, \nabla_X Z)$ são ortogonais a $W$,
	\begin{align*}
		\tilde{R}_m(X,Y,Z,W) &= \innerproduct{\nabla_X \nabla_Y Z + \tilde{\nabla}_X \alpha(Y,Z) - \nabla_Y \nabla_X Z - \tilde{\nabla}_Y \alpha(X,Z) - \nabla_{[X,Y]} Z}{W}\\
		&=  \innerproduct{\nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]} Z}{W} +  \innerproduct{\tilde{\nabla}_X \alpha(Y,Z)}{W} -  \innerproduct{\tilde{\nabla}_Y \alpha(X,Z)}{W}\\
		&=  \innerproduct{R(X,Y)Z}{W} +  \innerproduct{\tilde{\nabla}_X \alpha(Y,Z)}{W} -  \innerproduct{\tilde{\nabla}_Y \alpha(X,Z)}{W}\\
		&= R_m(X,Y,Z,W) +  \innerproduct{\tilde{\nabla}_X \alpha(Y,Z)}{W} -  \innerproduct{\tilde{\nabla}_Y \alpha(X,Z)}{W}.
	\end{align*}
	Usando a equação de Weingarten (lema \ref{equacao-de-weingarten}),
	\begin{equation*}
		\tilde{R}_m(X,Y,Z,W) = R_m(X,Y,Z,W) - \innerproduct{\alpha(X,W)}{\alpha(Y,Z)} + \innerproduct{\alpha(X,Z)}{\alpha(Y,W)}.
	\end{equation*}
\end{demonstracao}



\section{Curvaturas seccionais}

Os conceitos desenvolvidos em esta seção serão usados principalmente para o cálculo da curvatura intrínseca de uma superfície imersa em $S^3$.
Mencionará-se também, o fato que $S^3$ tem curvatura seccional constante igual a 1.

\begin{definicao}
	Seja $M$ uma $n$-variedade riemanniana e $p \in M$. Se $\Pi$ é um subespaço de $T_p M$ de dimensão 2, e $V \subset T_p M$ é uma vizinhança de zero  na qual $\exp_p$ é um difeomorfismo, então $S_{\Pi} = \exp_p(\Pi \cap V)$ é uma subvariedade de $M$ de dimensão 2 que contem a  $p$ chamada \emph{seção plana} determinada por $\Pi$.
\end{definicao}

\begin{definicao}
	A \emph{curvatura seccional} de $M$ associada $\Pi$, denotada por $K(\Pi)$, é a curvatura Gaussiana da superfície $S_{\Pi}$ em $p$ com a métrica induzida. Se $x,y$ é uma base para $\Pi$, é denotada também por $K(x,y)$.
\end{definicao}

\begin{proposicao}
	Seja $M$ uma $n$-variedade riemanniana e
	$R_m$ o tensor de curvatura de $M$.
	Se $\{ x,y \}$ é uma base para o subespaço vetorial $\Pi \subset T_p M$ de dimensão 2, então
	\begin{equation*}
	K(x,y) = \frac{R_m(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2}.
	\end{equation*}
\end{proposicao}

\begin{demonstracao}
	Seja $v \in \Pi$,
	$\lambda_v: [0,1] \rightarrow M$ geodésica com vetor inicial $v$,
	$D_t$ e $\tilde{D}_t$ as derivadas covariantes de caminhos em $M$ e $S_{\Pi}$ respectivamente, e
	$R_m$ e $\tilde{R}_m$ os tensores de curvatura para $M$ e $S_{\Pi}$ respectivamente.
	Pelo fato que $\lambda_v$ é uma geodésica tem-se $0 = D_t \lambda_v'$. Logo, usando a fórmula de Gauss para caminhos (proposição \ref{formula-de-gauss-para-caminhos}),
	\begin{equation*}
	0 = D_t \lambda_v' = \tilde{D}_t \lambda_v' + \alpha(\lambda_v', v)
	\end{equation*}
	Como $\tilde{D}_t \lambda_v'$ e $\alpha(\lambda_v',v)$ são ambos ortogonais, então ambos são zero. Para $t=0$ tem-se $\alpha(v,v) = 0$ para $v \in \Pi$ arbitrário. Como $\alpha$ é simétrico, então $\alpha \equiv 0$.
	Sejam $\{x,y\}$ uma base $\Pi$, então pela equação de Gauss (Teorema \ref{equacao-de-gauss}) tem-se
	\begin{equation*}
	R_m(x,y,y,x) = \tilde{R}_m(x,y,y,x)
	\end{equation*}
	e dai
	\begin{equation*}
	\frac{R_m(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2} = \frac{\tilde{R}_m(x,y,y,x)}{|x^2| |y|^2 - \innerproduct{x}{y}^2}.
	\end{equation*}
	Pela proposição \ref{relacion-tensor-de-curvatura-con-la-curvatura-gaussiana} tem-se
	\begin{equation*}
	K(x,y) = \frac{\tilde{R}_m(x,y,y,x)}{|x^2| |y|^2 - \innerproduct{x}{y}^2}.
	\end{equation*}
	Portanto
	\begin{equation*}
	K(x,y) = \frac{R_m(x,y,y,x)}{|x^2| |y|^2 - \innerproduct{x}{y}^2}.
	\end{equation*}
\end{demonstracao}

\begin{lema}\label{igualdade-de-4-tensores-covariantes}
	Supor $R_1,R_2: V^4 \rightarrow \R$ são aplicações multilineares em um espaço vetorial $V$ de dimensão maior que 2 com um produto interno, e que ambos tem as simetrias descritas na proposição \ref{simetrias-del-tensor-de-curvatura}. Se para cada par de vetores linearmente independentes $x,y \in V$,
	\begin{equation*}
	\frac{R_1(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2} = \frac{R_2(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2},
	\end{equation*}
	então $R_1 = R_2$.
\end{lema}

\begin{demonstracao}
	Seja $R = R_1 - R_2$.
	Para qualquer base $\{x,y\}$ de $V$ tem-se $R(x,y,y,x)=0$.
	Seja $\{x,y,z\} \in V$ um conjunto de vetores linearmente independentes. Então,
	\begin{align*}
	0 &= R(x+y,z,z,x+y)\\
	&= R(x,z,z,x) + R(x,z,z,y) + R(x,z,z,y) + R(y,z,z,y)\\
	&= 2R(x,z,z,y)
	\end{align*}
	Como $z$ é arbitrário, pudemos substituir-lo por $z+w$. Logo, a igualdade anterior pode-se escrever como
	\begin{align*}
	0 &= R(x,z+w,z+w,y)\\
	&= R(x,z,z,y) + R(x,z,w,y) + R(x,w,z,y) + R(x,w,w,y)\\
	&= R(x,z,w,y) + R(x,w,z,y).
	\end{align*}
	Pela propriedades da proposição \ref{simetrias-del-tensor-de-curvatura} tem-se
	\begin{align*}
	0 &= R(x,y,z,w) + R(y,z,x,w) + R(z,x,y,w)\\
	&= R(x,y,z,w) - R(y,x,z,w) - R(x,z,y,w)\\
	&= 3R(x,y,z,w).
	\end{align*}
	Portanto $R_1 = R_2$.
\end{demonstracao}

\begin{proposicao}
	Supor que $(M,g)$ é $n$-variedade riemanniana com curvatura seccional constante $C$. O endomorfismo de curvatura e o tensor de curvatura estão dados pelas formulas
	\begin{align*}
	R(X,Y)Z &= C(\innerproduct{Y}{Z}X - \innerproduct{X}{Z}Y),\\
	R_m(X,Y,Z,W) &= C(\innerproduct{X}{W} \innerproduct{Y}{Z} - \innerproduct{X}{Z} \innerproduct{Y}{W}).
	\end{align*}
\end{proposicao}

\begin{demonstracao}
	Seja $\Pi$ um subespaço vetorial de $T_p M$ de dimensão 2 para algum $p \in M$, $\{x,y\}$ uma base de $\Pi$ e $X,Y,Z,W \in \vectorfieldsspace{M}$. Como a variedade tem curvatura seccional constante $C$, então
	\begin{equation*}
	\frac{R_m(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2} = C.
	\end{equation*}
	Seja $R$ um 4-tensor covariante definido por
	\begin{equation*}
	R(x,y,z,w) = C (\innerproduct{x}{w} \innerproduct{y}{z} - \innerproduct{x}{z} \innerproduct{y}{w}).
	\end{equation*}
	Pode-se ver que $R$ cumpre as propriedades descritas na proposição \ref{simetrias-del-tensor-de-curvatura} e que
	\begin{equation*}
	\frac{R_m(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2} = \frac{R(x,y,y,x)}{|x|^2 |y|^2 - \innerproduct{x}{y}^2}.
	\end{equation*}
	Então, pelo lema \ref{igualdade-de-4-tensores-covariantes} tem-se que $R_m = R$. Portanto cumpre-se que
	\begin{equation*}
	R_m(X,Y,Z,W) = C(\innerproduct{X}{W} \innerproduct{Y}{Z} - \innerproduct{X}{Z} \innerproduct{Y}{W}).
	\end{equation*}
	A igualdade anterior pode-se escrever como
	\begin{equation*}
	\innerproduct{R(X,Y)Z}{W} =  \innerproduct{C(\innerproduct{Y}{Z}X - \innerproduct{X}{Z}Y)}{W}
	\end{equation*}
	com $W \in \vectorfieldsspace{M}$ arbitrário. Portanto
	\begin{equation*}
	R(X,Y)Z =  C(\innerproduct{Y}{Z}X - \innerproduct{X}{Z}Y).
	\end{equation*}
\end{demonstracao}

\begin{proposicao}
	$S^3$ tem curvatura seccional constante igual a 1.
\end{proposicao}

\begin{demonstracao}
	Ver \cite[Proposition 3.14, 3.47]{Gallot2004}.
\end{demonstracao}

\section{Hipersuperfícies em variedades riemannianas}

Em esta seção apresentará-se as propriedades que tem as subvariedades riemannianas de codimensão 1.
Tomou-se como referencias os livros \cite{Lee1997} e \cite{Gallot2004}.

\begin{definicao}
	Seja $M$ uma subvariedade riemanniana de codimensão 1 de $\tilde{M}$. $M$ é chamada de \emph{hipersuperfície}.
\end{definicao}

\begin{definicao}
	Seja $M$ uma hipersuperfície de $\tilde{M}$ e
	$N \in \vectorfieldsspace{M}^\perp$ tal que $|N_p|=1$ para todo $p \in M$.
	$N$ é chamado de \emph{campo vetorial normal unitário}.
\end{definicao}

%\begin{observacao}
%	Seja $M$ uma hipersuperfície de $\tilde{M}$ e 
%	$p \in M$.
Pode-se ver $N_p$ gera $\left(T_p M\right)^\perp$ porque $\left(T_p M\right)^\perp$ tem dimensão 1.
%\end{observacao}

\begin{definicao}
	Seja $M$ uma hipersuperfície de $\tilde{M}$,
	$N$ o campo de vetores normais unitário e
	$X,Y \in \vectorfieldsspace{M}$.
	A aplicação $h: \vectorfieldsspace{M}^2 \rightarrow \smoothfunctionsspace{M}$ definida por
	\begin{equation*}
	h(X,Y) = \innerproduct{\alpha(X,Y)}{N},
	\end{equation*}
	é chamada \emph{segunda forma fundamental escalar de $M$}.
\end{definicao}
%\begin{observacao}
%	Seja $M$ uma hipersuperfície em $\tilde{M}$,
%	$X,Y \in \vectorfieldsspace{M}$,
%	$h$ a segunda forma fundamental escalar de $M$ e
%	$N$ o campo de vetores normais unitários.
	Como $\alpha(X,Y)$ e $N$ são paralelos, podemos escrever
	\begin{equation*}
	\alpha(X,Y) = h(X,Y) N.
	\end{equation*}
%\end{observacao}
%\begin{observacao}
%	Seja $M$ uma hipersuperfície de $\tilde{M}$,
%	$p \in M$ e 
%	$x,y \in T_p M$.
%	Em $p$, $h$ é uma forma bilinear simétrica.
$h$ em $p$ tem associada um operador linear $A: T_p M \rightarrow T_p M$ autoadjunto tal que
	\begin{equation*}
	h(x,y) = \innerproduct{Ax}{y} = \innerproduct{x}{Ay}.
	\end{equation*}
%\end{observacao}
%\begin{observacao}
%	Seja $M$ uma hipersuperfície em $\tilde{M}$ e
%	$p \in M$.
	Como $A$ é um operador linear autoadjunto, então os seus autovalores são reais e os seus autovetores geram uma base ortonormal de $T_p M$.
%\end{observacao}

\begin{definicao}
	Seja $M$ uma hipersuperfície de $\tilde{M}$,
	$p \in M$ e
	$A$ o operador autoadjunto associado à segunda forma fundamental escalar de $M$ no ponto $p$.
	Os autovalores de $A$ são chamados de \emph{curvaturas principais}.
\end{definicao}

%\begin{definicao}
%	Seja $M$ uma hipersuperfície de $\tilde{M}$,
%	$p \in M$,
%	$\Pi \subset T_p M$ um subespaço de dimensão 2,
%	$\{u,v\}$ uma base de $\Pi$ e
%	$h$ a segunda forma fundamental escalar de $M$.
%	A \emph{curvatura gaussiana} $\overline{K}$ de $\Pi$ está definida por
%	\begin{equation*}
%	\overline{K} = \frac{h(u,u) h(v,v) - h(u,v)^2}{\innerproduct{u}{u} \innerproduct{v}{v} - \innerproduct{u}{v}^2}
%	\end{equation*}
%\end{definicao}

\begin{definicao}\label{def:curvatura-media}
	Seja $M$ uma hipersuperfície de $\tilde{M}$,
	$p \in M$ e
	$A$ o operador autoadjunto associado à segunda forma fundamental escalar de $M$ em $p$.
	A \emph{curvatura média} está definida por
	\begin{equation*}
	H(p) = \text{tr} A.
	\end{equation*}
\end{definicao}

\begin{corolario}\label{equacao-de-gauss-hipersuperficies}
	Seja $M$ uma hipersuperfície em $\tilde{M}$;
	$X,Y,Z,W \in \vectorfieldsspace{M}$,
	$h$ a segunda forma fundamental escalar de $M$ e
	$\tilde{R}_m, R_m$ os tensores de curvaturas de $\tilde{M}$ e $M$ respectivamente.
	Então
	\begin{equation*}
	\tilde{R}_m(X,Y,Z,W) = R_m(X,Y,Z,W) - h(X,W) h(Y,Z) + h(X,Z) h(Y,W)
	\end{equation*}
\end{corolario}

\begin{demonstracao}
	Pela equação de Gauss (teorema \ref{equacao-de-gauss}) e como $\alpha(X,Y)= h(X,Y) N$ para $X,Y \in \vectorfieldsspace{M}$,
	\begin{equation*}
	\tilde{R}_m(X,Y,Z,W) = R_m(X,Y,Z,W) - \innerproduct{h(X,W) N}{h(Y,Z) N} + \innerproduct{h(X,Z)N}{h(Y,W)N}.
	\end{equation*}
	Pelo fato que $|N|=1$,
	\begin{equation*}
	\tilde{R}_m(X,Y,Z,W) = R_m(X,Y,Z,W) - h(X,W) h(Y,Z) + h(X,Z) h(Y,W).
	\end{equation*}
\end{demonstracao}

%\begin{definicao}
%	Seja $M$ uma hipersuperfície de $\tilde{M}$ e
%	$A$ o operador linear autoadjunto associado à segunda forma fundamental escalar de $M$.
%	A \emph{curvatura gaussiana} está definida por
%	\begin{equation*}
%		K(p) = \det A
%	\end{equation*}
%\end{definicao}

%\begin{definicao}
%	Seja $M$ uma hipersuperfície de $\tilde{M}$ e
%	$A$ o operador associado à segunda forma fundamental escalar de $M$.
%	A \emph{curvatura média} está definida por
%	\begin{equation*}
%		H(p) = \frac{1}{n} \text{tr} A 
%	\end{equation*}
%\end{definicao}

%\begin{proposicao}\label{relacion-tensor-de-curvatura-con-la-curvatura-gaussiana}
%	Seja $M$ uma 2-variedade riemanniana e
%	$X,Y,Z,W \in \vectorfieldsspace{M}$.
%	A curvatura Gaussiana $K$ de $M$ está relacionada com o tensor de curvatura pela fórmula
%	\begin{equation*}
%		R_m(X,Y,Z,W) = K (\innerproduct{X}{W} \innerproduct{Y}{Z} - \innerproduct{X}{Z} \innerproduct{Y}{W})
%	\end{equation*}
%\end{proposicao}



%\begin{definicao}\label{def:curvatura-media}
%	Seja $M$ uma variedade imersa em $\tilde{M}$,
%	$E_1, E_2$ um referencial de $M$ e
%	$\alpha$ a segunda forma fundamental de $M$.
%	A \emph{curvatura média} $H \in \vectorfieldsspace{M}^\perp$ está definida por
%	\begin{equation*}
%		H = \sum_{i=1}^2 \alpha(E_i, E_i)
%	\end{equation*}
%\end{definicao}